{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating an Agent using Large Language Models (LLMs)\n",
    "\n",
    "**Goal:** Create a natural language interface for a simple API that reads / write to a redis cache as a proof of concept. \n",
    "\n",
    "Examples: \n",
    "1. Create a new record for a new user Ryan Skinner, locaed in Denver Colorado\n",
    "2. Retreieve a record for the user Ryan Skinner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Configuration of the OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ssl\n",
    "import json\n",
    "\n",
    "from openai import OpenAI\n",
    "from ddtrace.llmobs import LLMObs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the secrets\n",
    "with open(\"secrets.json\") as f:\n",
    "    secrets = json.load(f)\n",
    "DD_API_KEY = secrets[\"DD_API_KEY\"]\n",
    "DD_SITE = secrets[\"DD_SITE\"]\n",
    "OAI_API_KEY = secrets[\"OAI_API_KEY\"]\n",
    "\n",
    "# Enable the integration\n",
    "LLMObs.enable(\n",
    "    integrations_enabled=True, \n",
    "    ml_app=\"skinner-OAi-llm-agent\", \n",
    "    api_key = DD_API_KEY,\n",
    "    site = DD_SITE,\n",
    "    agentless_enabled = True,\n",
    "    env=\"test\",\n",
    "    service=\"llm-agent\"\n",
    ")\n",
    "\n",
    "# Establish the Client\n",
    "client = OpenAI(api_key=OAI_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing if the Client Works\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-4o-mini\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with\"\n",
    "                                  \" creative flair.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Can you write a haiku about kubernetes\"}\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Clusters dance in sync,  \\nPods afloat on orchestration,  \\nCloud's dream takes its flight.  \", refusal=None, role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='2 + 2 = 4', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 7, 'prompt_tokens': 14, 'total_tokens': 21}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-0d6ac765-a803-4840-ae20-1d7b48f481c0-0', usage_metadata={'input_tokens': 14, 'output_tokens': 7, 'total_tokens': 21})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(api_key=OAI_API_KEY)\n",
    "llm.invoke(\"What is 2+2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='2 + 2 equals 4.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 24, 'total_tokens': 32}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-10bd2d9f-4414-4156-bc1b-656278c4c420-0', usage_metadata={'input_tokens': 24, 'output_tokens': 8, 'total_tokens': 32})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "prompt = ChatPromptTemplate.from_messages([ \n",
    "    (\"system\",\"You are chatGPT\"), \n",
    "    (\"user\",\"{input}\")\n",
    "])\n",
    "chain = prompt | llm\n",
    "chain.invoke(\"What is 2 + 2?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt engineering to classify a users text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are responsible for classifying a users request as the following \n",
      "    1. A request to add a user to the database \n",
      "    2. Update the user information to the database\n",
      "    3. Retrieve information about the user from the database\n",
      "\n",
      "The only valid responses are ADD, UPDATE, RETRIEVE, UNKNOWN\n",
      "\n",
      "If the user intends to add a user respond with ADD\n",
      "If the user intends to update user information in the database respond with UPDATE\n",
      "If the user inteds to retrieve information from the database respond with RETRIEVE\n",
      "If unknown or uncertain respond with UNKNOWN\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"You are responsible for classifying a users request as the following \\n\\\n",
    "    1. A request to add a user to the database \\n\\\n",
    "    2. Update the user information to the database\\n\\\n",
    "    3. Retrieve information about the user from the database\\n\\n\\\n",
    "The only valid responses are ADD, UPDATE, RETRIEVE, UNKNOWN\\n\\n\\\n",
    "If the user intends to add a user respond with ADD\\n\\\n",
    "If the user intends to update user information in the database respond with UPDATE\\n\\\n",
    "If the user inteds to retrieve information from the database respond with RETRIEVE\\n\\\n",
    "If unknown or uncertain respond with UNKNOWN\"\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    (\"user\",\"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='RETRIEVE', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 4, 'prompt_tokens': 136, 'total_tokens': 140}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-69916451-b2b5-4279-97ef-7433d83a3a15-0', usage_metadata={'input_tokens': 136, 'output_tokens': 4, 'total_tokens': 140})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm\n",
    "chain.invoke(\"Where does Ryan live?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
